# Data Science Portfolio: Cybersecurity Focus

## Table of Contents
1. [Overview](#1-overview)
2. [Key Lessons Learned](#2-key-lessons-learned)
3. [Solution Summary](#3-solution-summary)
    - [3.1 Data Preprocessing](#31-data-preprocessing)
        - [3.1.1 Introduction](#311-introduction)
        - [3.1.2 Data Cleaning](#312-data-cleaning)
        - [3.1.3 Feature Categorization and Encoding](#313-feature-categorization-and-encoding)
        - [3.1.4 Feature Engineering](#314-feature-engineering)
    - [3.2 Modeling](#32-modeling)
        - [3.2.1 M1](#321-m1)
            - [3.2.1.1 Hyperparameter Settings Used](#3211-hyperparameter-settings-used)
            - [3.2.1.2 Impact of Each Hyperparameter on Model Performance](#3212-impact-of-each-hyperparameter-on-model-performance)
            - [3.2.1.3 Additional Hyperparameters to Consider](#3213-additional-hyperparameters-to-consider)
    - [3.3 Validation Strategy](#33-validation-strategy)
4. [Requirements](#4-requirements)
5. [Usage](#5-usage)
6. [Reflections](#6-reflections)
7. [Links](#7-links)
8. [Appendix](#8-appendix)
    - [8.1 Appendix A: Understanding Label Encoding and Frequency Encoding](#81-appendix-a-understanding-label-encoding-and-frequency-encoding)
    - [8.2 Appendix B: Common Encoding Methods and Their Applications in Cybersecurity](#82-appendix-b-common-encoding-methods-and-their-applications-in-cybersecurity)

# 1. Overview
This repository documents my journey and learning from participating in the [Microsoft Malware Prediction competition on Kaggle](https://www.kaggle.com/c/microsoft-malware-prediction). The goal of this competition was to predict the probability that a machine running Windows 10 could be susceptible to malware attacks, based on various system features provided by Microsoft.

# 2. Key Lessons Learned
- **Emulating Real-World Solutions:** The approach focused on creating a model that could realistically be implemented in a production environment, not just optimized for competition scores.
- **Handling Large Datasets:** Developed strategies for managing and processing large datasets efficiently to prepare the data for modeling.

# 3. Solution Summary

## 3.1 Data Preprocessing

### 3.1.1 Introduction
Data preprocessing is a critical step in the data science workflow, especially in the context of cybersecurity. It involves cleaning and transforming raw data into a format that is suitable for analysis and modeling. This section will discuss various data preprocessing techniques used in this project, explaining their importance in a way that is accessible to non-technical business executives.

### 3.1.2 Data Cleaning
The Data Cleaning Process is essential for ensuring the quality and usability of the data. Here's an overview of the key steps involved and their significance:

#### Feature Removal
**Missing Values:** Features with too many NaN (missing) values are deleted because they can skew the analysis and might lead to unreliable models. A threshold of 90% missing values is generally considered as a criterion for removal, as it indicates that the feature is largely absent and likely not useful for predictive modeling.

<img src="img/features_with_high_nan.png" alt="nan_features" width="900"> 

*Figure 1: Missing Values - This table shows the featurew with the highest percentages of missing values.  For example: PuaMode and Census_ProcessorClass have 99%+ missing values.*

**Unbalanced Features:** Features with highly unbalanced dimensions are deleted. For example, a feature where a single category dominates can be less informative for modeling. A common threshold for considering a feature as unbalanced is when more than 95% of the values are concentrated in one category. This high concentration means the feature will not contribute significantly to the model's ability to distinguish between different observations.

Unbalanced Featues Table                              | Unbalanced IsBeta Feature
:---------------------------------------------------: | :---------------------------------------------------:
<img src="img/unbalanced_features.png" alt="HTML Table Target" width="450">  | <img src="img/umbalanced_feature_bar_chart.png" alt="HTML Table Target" width="610"> 

*Figure 2: Unbalanced Features - There are 26 columns in total in which one category contains > or = 90% of the values (left) and esentially 100% of IsBeta values belong to IsBeta (right). *

### 3.1.3 Feature Categorization and Encoding
Proper categorization and encoding of features are crucial as they directly influence the accuracy and efficiency of predictive models. They ensure that the algorithm correctly interprets the data, respects the nature of the data, and helps in achieving better performance. Features are split into three main types: binary, numeric, and categorical. Each type requires specific handling to ensure optimal data structure for machine learning algorithms:

#### General Data Type Encoding Guidance

**Binary Features:**
- **Definition:** Features with only two possible values (e.g., 0 or 1, Yes or No).
- **Encoding Best Practices:** Binary features are often left as-is if they are already in numeric format (0 and 1). If binary features are in text format (e.g., Yes/No), they should be encoded to 0 and 1 respectively.
- **Importance:** Proper handling ensures that models interpret these features correctly without additional transformation complexity.

**Numeric Features:**
- **Definition:** Features with quantitative values that can be measured.
- **Encoding Best Practices:** Numeric features may be scaled or normalized to ensure that no single feature dominates the model due to its scale.
- **Importance:** Scaling or normalizing numeric features helps in speeding up the learning process of algorithms and improves model performance.

**Categorical Features:**
- **Definition:** Features with a fixed number of categories or distinct groups.
- **Encoding Best Practices:** Categorical variables are typically encoded using techniques such as one-hot encoding, label encoding, or using embedding layers if using neural networks.
- **Importance:** Encoding transforms categorical data into a format that can be easily used by machine learning algorithms to better understand the patterns within the data.

#### Encoding Methods Used
- **Label Encoding:** Transforms categorical feature labels into numeric form ranging from `0` to `N-1`, where `N` is the number of different labels. This is typically used for categorical features that have a natural ordinal relationship.

- **Frequency Encoding:** A variant of label encoding where features are encoded based on the frequency of their values. The encoded numbers range from `0` to `N`, where `N` is the number of values that occur more than once. This method is effective for categorical data where the frequency of values may have a predictive power.

- [Appendix A: Understanding Label Encoding and Frequency Encoding](#81-appendix-a-understanding-label-encoding-and-frequency-encoding)
- [Appendix B: Common Encoding Methods and Their Applications in Cybersecurity](#82-appendix-b-common-encoding-methods-and-their-applications-in-cybersecurity)

# Data Science Portfolio: Cybersecurity Focus

## Table of Contents
1. [Overview](#1-overview)
2. [Key Lessons Learned](#2-key-lessons-learned)
3. [Solution Summary](#3-solution-summary)
    - [3.1 Data Preprocessing](#31-data-preprocessing)
        - [3.1.1 Introduction](#311-introduction)
        - [3.1.2 Data Cleaning](#312-data-cleaning)
        - [3.1.3 Feature Engineering](#313-feature-engineering)
    - [3.2 Modeling](#32-modeling)
    - [3.3 Validation Strategy](#33-validation-strategy)
4. [Requirements](#4-requirements)
5. [Usage](#5-usage)
6. [Reflections](#6-reflections)
7. [Links](#7-links)


### 3.1.4 Feature Engineering Techniques Used in Model M2

#### Introduction
In developing our second model, M2, for cybersecurity threat detection, we have employed a variety of advanced feature engineering techniques. These techniques not only enhance the model's predictive power but also ensure that it can effectively handle the complexities associated with cybersecurity data. The feature engineering process involved transforming raw data into more informative features that improve detection capabilities and model robustness.

#### Specific Techniques Employed

**Domain-Specific Features**:
- **Primary Drive C Ratio**: This feature represents the ratio of the system volume total capacity to the primary disk total capacity. It is a domain-specific feature that helps in assessing the usage pattern of the primary drive which might be indicative of unusual behaviors if the ratios are outliers.
- **Non-Primary Drive MB**: Represents the unused capacity of the primary disk. This feature is useful for identifying potential red flags where the primary disk usage is inconsistent with typical user behavior.

**Polynomial and Interaction Features**:
- **Aspect Ratio and Screen Area**: These features are derived by interacting screen resolution dimensions and diagonal display size. They represent the physical characteristics of the display used by the system, which can be crucial for identifying fraudulent activities where display resolution manipulation is common.
- **ProcessorCoreCount_DisplaySizeInInches**: An interaction feature that multiplies the processor core count with the diagonal display size, capturing a compound metric that could be critical in systems analysis within cybersecurity contexts.

**Aggregation Features**:
- **Ram Per Processor**: Represents the average RAM available per processor core, calculated by dividing the total physical RAM by the number of processor cores. This feature aggregates system specifications into a single metric that could be indicative of performance capabilities or potential bottlenecks.

**Encoding Techniques**:
- **Monitor Dims and SmartScreen_AVProductsInstalled**: Both features utilize categorical encoding to transform text descriptions into a machine-readable format. `Monitor Dims` captures the combined dimensions of the monitor, while `SmartScreen_AVProductsInstalled` combines the SmartScreen settings with the number of installed antivirus products for a nuanced look at system security posture.
  - **Label Encoding**: Applied to `Monitor Dims` to convert dimensions into a numeric format that preserves the ordinal nature without increasing dimensionality.
  - **Frequency Encoding**: Used for `SmartScreen_AVProductsInstalled` to reflect the prevalence of each configuration within the dataset, providing a weight to more common or rare configurations.
#### Integration into Datasets
The new features were integrated into the existing datasets and stored accordingly:
- **Training Data**: `../data/train_featureengineering_M2.csv`
- **Testing Data**: `../data/test_featureengineering_M2.csv`

These features were encoded and included in the model training process for M2, aimed at improving the predictive accuracy by providing new angles and information vectors. The integration process involved careful handling of categorical variables and normalization of numerical features to align with machine learning algorithms' requirements.

#### Feature Encoding Strategy
The newly created features required appropriate encoding to ensure they are correctly interpreted by the machine learning algorithms:
- **Label Encoding**: Applied to features like `monitor_dims` and `SmartScreen_AVProductsInstalled`, converting string labels into integers.
- **Categorical Encoding**: Used for features that represent categories with significant ordinal relationships and require model understanding of the hierarchy within the data.

### Summary
Feature engineering is a critical step in enhancing model performance. By thoughtfully creating and integrating new features, we aim to capture more complexity and provide our models with a deeper understanding of the data, which is crucial for detecting and predicting cybersecurity threats more effectively.

## 3.2 Modeling

### 3.2.1 M1
**Model M1 Summary:**
Model M1 implements the [LightGBM](https://github.com/rexcoleman/Data-Science-Model-Selection-in-Cybersecurity/blob/main/README.md#lightgbm) method, leveraging its high efficiency with large datasets and categorical features. The model training involved setting hyperparameters that were optimized through Bayesian Hyperparameter Optimization using a 3-fold Cross Validation to ensure robustness and high performance.

**Model Training and Validation:**
The model was trained using a variety of features selected based on their importance and relevance to the task. After training, the model's performance was validated using data from the test set, ensuring that it generalizes well to new, unseen data. The features used were sorted by their importance, which was crucial for understanding the driving factors behind the model's predictions.

**Technical Details:**
- **Training Data:** Data was prepared and encoded appropriately before training to handle different types of features effectively.
- **Hyperparameters:** Tuned using Bayesian optimization to find the best combination that maximizes the model's accuracy.
- **Validation:** Employed a 3-fold Cross Validation strategy during the tuning phase to validate the model's effectiveness across different subsets of the data.

**Model Saving and Prediction:**
The trained model was saved to disk, allowing for reproducibility and later use in operational settings. Predictions were made on the test set, and the output was prepared for submission, showcasing the practical application of the model in a competitive scenario.

**Feature Importance:**
A comprehensive list of features sorted by their importance was generated, providing insights into what factors most significantly impact malware detection. This analysis helps in refining the model further by focusing on the most impactful features.

**Outputs:**
- Model file: `../models/model_M1.p`
- Feature importance file: `../feature_importances/FeatureImportance_M1.csv`
- Submission file: `../submissions/Submission_M1.csv`

### 3.2.1.1 Hyperparameter Settings Used:
The following hyperparameters were finely tuned to optimize the LightGBM model for the Microsoft Malware Prediction competition:

- **Boosting Type**: 'gbdt' (Gradient Boosting Decision Tree)
- **Class Weight**: None
- **Colsample by Tree**: 0.611
- **Learning Rate**: 0.0106
- **Min Child Samples**: 295
- **Num Leaves**: 160
- **Reg Alpha**: 0.632
- **Reg Lambda**: 0.631
- **Subsample for Bin**: 80,000
- **Subsample**: 0.820

### 3.2.1.2 Impact of Each Hyperparameter on Model Performance
Understanding how each hyperparameter influences the model can help in fine-tuning and achieving better performance:

- **Boosting Type**: Specifies the type of algorithm to run. 'gbdt' is the standard gradient boosting decision tree, known for its effectiveness in classification tasks.
- **Class Weight**: Used to handle imbalanced classes. If not specified, all classes are supposed to have weight one.
- **Colsample by Tree**: Fraction of features (columns) to be used per tree. Reducing this can prevent overfitting.
- **Learning Rate**: Determines the step size at each iteration while moving toward a minimum of a loss function. Lower rates require more trees but can lead to better accuracy.
- **Min Child Samples**: Minimum number of data points in a leaf. If this is set too low, the model might overfit.
- **Num Leaves**: The maximum number of leaves in one tree. More leaves will increase accuracy but may cause overfitting.
- **Reg Alpha** (L1 regularization): This is used on weights. Increasing this value will make the model more conservative.
- **Reg Lambda** (L2 regularization): Similar to L1 but differently influences the magnitude of weights. It effectively reduces overfitting.
- **Subsample for Bin**: Number of subsamples to use for constructing bins. Affects the speed of the construction algorithm.
- **Subsample**: Ratio of the training instance. Setting it to 0.8 means LightGBM will randomly sample 80% of the data for building trees and can help in preventing overfitting.

### 3.2.1.3 Additional Hyperparameters to Consider
Exploring more hyperparameters could further enhance model performance:

- **Max Depth**: Limits the number of nodes in the tree. Tune it from 3 to 10 for different depth levels to control over-fitting.
- **Feature Fraction**: Try values between 0.5 to 0.8 to give a random subset of features for each tree to train on, which can help in improving accuracy and control overfitting.
- **Bagging Frequency**: Specifies how often bagging is used. Increasing this number could be beneficial if subsample < 1.
- **Early Stopping Rounds**: Specify a number of iterations over which, if performance does not improve, training will stop. This can prevent overfitting and reduce computational waste.

These additional settings can be explored using grid or random search to find the best combination that improves the overall accuracy and robustness of the model in detecting malware.




## 3.3 Validation Strategy
- Ensured a robust validation strategy that mimics real-world deployment rather than optimizing for leaderboard position, emphasizing the importance of model generalization.

# 4. Requirements
- **Python Version:** 3.7.1
- **Major Libraries:** pandas, numpy, lightgbm, scikit-learn

# 5. Usage
1. **Data Preparation:** Run the notebooks under `notebooks/` to clean and prepare data.
2. **Model Training:** Execute model training scripts to train and save the model.
3. **Evaluation:** Evaluate the model's performance on a separate validation set to ensure generalizability.

# 6. Reflections
Participating in this competition offered invaluable insights into the practical aspects of machine learning projects, including the importance of data quality, thoughtful feature engineering, and the need for robust validation methods.

# 7. Links
- [Competition Data](https://www.kaggle.com/c/microsoft-malware-prediction/data)
- [My Kaggle Profile](https://www.kaggle.com/yourusername)

# 8. Appendix

## 8.1 Appendix A: Understanding Label Encoding and Frequency Encoding

When preparing data for machine learning models, particularly those that handle categorical data, it is crucial to convert the data into a format that can be effectively processed by algorithms. Label encoding and frequency encoding are two popular methods for transforming categorical data into numerical data, each serving distinct purposes and suitable for different scenarios. This section outlines these encoding techniques, providing insights into when and why each method should be used.

### Label Encoding
Label encoding is a straightforward method where each unique category value is assigned a unique integer. For example, if a feature such as `Color` has three categories: Red, Yellow, and Blue, label encoding would replace them with 0, 1, and 2 respectively. This method is efficient in terms of memory and simplicity, making it a common first choice for transforming categorical data into a usable format for algorithms that require numerical input, such as logistic regression, support vector machines, and other linear models.

**Advantages of Label Encoding:**
1. **Simplicity:** It is straightforward to implement and doesn't increase the data dimensionality.
2. **Efficiency:** Requires less computational power and memory, which makes it suitable for large datasets.

**Disadvantages of Label Encoding:**
1. **Ordinality:** Label encoding can introduce an artificial order or hierarchy among categories, where none exists. For instance, assigning Yellow = 1 and Red = 2 might lead the model to believe that Red is greater than Yellow, which might not be a meaningful or desired interpretation.
2. **Limited Application:** Not suitable for models that assume a natural ordering between categories, such as tree-based models, unless the ordinal relationship is intended.

### Frequency Encoding
Frequency encoding, a variant of label encoding, assigns values to categories based on their frequencies. This method counts how many times each category appears in the dataset and then replaces the categories with these counts. This encoding method is particularly useful when the frequency of the category itself might be a predictive signal. For instance, in fraud detection, more frequent categories might be more closely associated with specific outcomes.

**Advantages of Frequency Encoding:**
1. **Preserves Information:** By encoding categories based on their frequencies, it retains information about the dataset's distribution that could be useful for some models.
2. **Non-linear Relationships:** More suitable for non-linear models that can understand and leverage the frequency-based ordering of categories.

**Disadvantages of Frequency Encoding:**
1. **Collisions:** Different categories might end up with the same frequency, thus receiving the same encoding. This can cause a loss of information as distinct categories are treated similarly.
2. **Overfitting:** Models might overfit to the frequency of categories seen in the training data, which might not generalize well to unseen categories or different distributions in the test set.

### When to Use Each Method
Choosing between label encoding and frequency encoding often depends on the nature of the data and the type of model being used:

- **Label Encoding** is generally better when:
  - The categorical feature is ordinal.
  - The number of categories is quite large as it does not expand the feature space.
  - The learning algorithm you are using does not assume any order (e.g., tree-based methods).

- **Frequency Encoding** works well when:
  - The frequency of occurrence of category values is important for the prediction.
  - The model can handle non-linear relationships well, like random forests or gradient boosting machines.

In practice, the choice of encoding might also depend on experimentation. It is often a good idea to try multiple encoding methods during the feature engineering phase and compare their performance using cross-validation. This empirical approach helps identify which method works best for the specific characteristics of the data and the predictive model.


## 8.2 Appendix B: Common Encoding Methods and Their Applications in Cybersecurity

This section outlines various encoding methods for categorical data, their advantages, disadvantages, and examples of applications in cybersecurity. Choosing the correct encoding technique is crucial as it can greatly affect the performance of machine learning models.

### 1. **Label Encoding**
- **Description:** Assigns a unique integer to each category based on alphabetical order.
- **Pros:** Efficient and simple.
- **Cons:** Implies an ordinal relationship which may not exist.
- **Cybersecurity Example:** Encoding threat levels (Low, Medium, High) in security logs.

### 2. **Frequency Encoding**
- **Description:** Replaces categories with their occurrence counts.
- **Pros:** Keeps information about category frequency.
- **Cons:** Can merge different categories if they have the same frequency.
- **Cybersecurity Example:** Encoding frequency of access to sensitive system resources.

### 3. **One-Hot Encoding**
- **Description:** Creates a new binary column for each category.
- **Pros:** Does not assume ordinality between categories.
- **Cons:** Increases dataset dimensionality significantly.
- **Cybersecurity Example:** Encoding HTTP methods (GET, POST, DELETE) in web traffic data.

### 4. **Binary Encoding**
- **Description:** Converts categories into binary codes.
- **Pros:** More compact than one-hot encoding.
- **Cons:** Introduces multiple columns.
- **Cybersecurity Example:** Encoding network protocol types.

### 5. **Hashing**
- **Description:** Uses a hash function to encode categories into integers.
- **Pros:** Efficient with high cardinality features.
- **Cons:** Potential hash collisions.
- **Cybersecurity Example:** Anonymizing IP addresses in large datasets.

### 6. **BaseN Encoding**
- **Description:** Generalization of binary encoding using any base N.
- **Pros:** More flexible and efficient than one-hot encoding.
- **Cons:** Complexity can increase with larger N.
- **Cybersecurity Example:** Encoding software version numbers.

### 7. **Mean (Target) Encoding**
- **Description:** Replaces categories with the average value of the target for that category.
- **Pros:** Can improve model performance.
- **Cons:** Risk of overfitting.
- **Cybersecurity Example:** Encoding country codes in fraud detection systems based on fraud rates.

### 8. **Weight of Evidence Encoding**
- **Description:** Quantifies the predictive power of a category with respect to the target.
- **Pros:** Provides interpretable encoding.
- **Cons:** Biased by rare categories.
- **Cybersecurity Example:** Encoding user roles for predicting security policy violations.

### 9. **Ordinal Encoding**
- **Description:** Converts categories to integers based on the order.
- **Pros:** Minimal feature expansion.
- **Cons:** Assumes an order that might not exist.
- **Cybersecurity Example:** Encoding risk ratings from security tools.

### 10. **Leave-One-Out Encoding**
- **Description:** Similar to target encoding but reduces overfitting by excluding the current row's category while calculating the mean.
- **Pros:** Reduces overfitting risk.
- **Cons:** Computationally intensive.
- **Cybersecurity Example:** Encoding asset tags when assessing compromise risks.

### 11. **Backward Difference Encoding**
- **Description:** Compares the mean of the dependent variable for one level to the mean of the previous level.
- **Pros:** Useful for ordinal data with linear relationships.
- **Cons:** Assumes linear relationships.
- **Cybersecurity Example:** Encoding levels of security software upgrades.

### 12. **Helmert Encoding**
- **Description:** Compares each level of a categorical variable to the mean of the subsequent levels.
- **Pros:** Does not assume a starting point.
- **Cons:** Complex and harder to interpret.
- **Cybersecurity Example:** Useful in experimental designs in cybersecurity studies.

## Conclusion
The selection of an encoding method should consider the specific characteristics of the data, the machine learning model requirements, and the particular domain of application. In cybersecurity, where accuracy and interpretability are crucial, the right choice of encoding can significantly enhance model performance.
