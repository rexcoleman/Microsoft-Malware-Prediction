# Microsoft Malware Prediction: Kaggle Competition

## Overview
This repository documents my journey and learning from participating in the [Microsoft Malware Prediction competition on Kaggle](https://www.kaggle.com/c/microsoft-malware-prediction). The goal of this competition was to predict the probability that a machine running Windows 10 could be susceptible to malware attacks, based on various system features provided by Microsoft.

## Key Lessons Learned
- **Emulating Real-World Solutions:** The approach focused on creating a model that could realistically be implemented in a production environment, not just optimized for competition scores.
- **Handling Large Datasets:** Developed strategies for managing and processing large datasets efficiently to prepare the data for modeling.

## Solution Summary
The solution was inspired by the 2nd place winner's approach but adapted for educational and replication purposes to learn best practices in handling real-world large data scenarios.

### Data Preprocessing
- **Cleaning:** Removed features with excessive missing values and segmented features into numerical, binary, and categorical for specialized preprocessing.
- **Feature Engineering:** Classified and encoded features appropriately, managing missing values based on the type of data (e.g., mode for binary features).

### Modeling
- **Model Selection:** Utilized LightGBM for its efficiency with large datasets and categorical features handling.
- **Parameter Tuning:** Conducted parameter tuning to optimize the LightGBM model, ensuring the best possible performance.

### Validation Strategy
- Ensured a robust validation strategy that mimics real-world deployment rather than optimizing for leaderboard position, emphasizing the importance of model generalization.


## Requirements
- **Python Version:** 3.7.1
- **Major Libraries:** pandas, numpy, lightgbm, scikit-learn

## Usage
1. **Data Preparation:** Run the notebooks under `notebooks/` to clean and prepare data.
2. **Model Training:** Execute model training scripts to train and save the model.
3. **Evaluation:** Evaluate the model's performance on a separate validation set to ensure generalizability.

## Reflections
Participating in this competition offered invaluable insights into the practical aspects of machine learning projects, including the importance of data quality, thoughtful feature engineering, and the need for robust validation methods.

## Links
- [Competition Data](https://www.kaggle.com/c/microsoft-malware-prediction/data)
- [My Kaggle Profile](https://www.kaggle.com/yourusername)
